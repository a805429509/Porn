# Porn
这个项目是用来学习的，采用的都是404网站。
所以要是拿来用作其他用途，你起码也学了一下下知识，当是奖励吧。。


> 采用scrapy+mongodb+schedule+subprocess，可以配置使用supervisor来进行控制

### 使用

`scrapy crawlall`进行所有的爬虫全量爬取
`scrapy crawlall -i`进行所有的爬虫增量爬取

### 功能
1. 可以解析在线mp4的时长信息
> 分辨率和fps个人觉得在这个项目里没什么用。同一个地址请求次数过多可能会被ban，影响爬虫效率。而一次把moov都请求下来，可能会有好几mb大小，同样影响爬虫的效率。
> 实在有需求的话推荐使用construct，参考 [此项目](https://github.com/manfrommars/mp4_parser/)， [还有一个](https://github.com/beardypig)


### 20180507
> 准备抓取jav777网站，发现是blob，采用m3u8分割视频。用`ffmpeg -i "m3u8_url" name.mp4`去下载。虽然下载速度一般般，但是比起下载以后再整合文件，要好的多。

### 20180509
> 被jav777这个网站折磨了2天，原因
1. 发现这个网站如果用手机登录，会出现mp4路径，而不是m3u8.所以开始研究。。
2. 这个网站`onload`以后执行`init()`，发送了`ajax`请求，然后把`video`标签加载出来。所以必须要能爬取动态页面。而且第一次是`m3u8`，第二次`mp4`。都是通过ajax获取到`加密后的js代码`，然后直接`eval()`执行。
参考了`scrapy-splash`,`selenium`,`Pyppeteer`
3. `scrapy-splash`不知道为什么，设置了headers和等待页面完成20秒，还是m3u8地址。还得去研究调试splash。。而且根据splash的官方文档貌似还要学一点lua的知识，才能wait出来想要的结果(所以我才设置等待20秒)。。同时splash是一个单独的docker项目(不用docker又会很麻烦)，我需要在爬虫开始的时候保存运行，爬取完成后关闭docker，增加了工作量和复杂度。所以虽然说它很受欢迎，但是工作量好大啊，事情会变得很复杂。
4. `Pyppeteer`是`chrome`官方`ppeteer`的非官方封装。看了以下launch部分，通过远程操作一个运行的chrome来实现。和上面一样，也要保持浏览器处于运行状态，同时允许远程连接调用。也需要我自己来关闭，可是我想偷懒啊。。偷懒才是第一生产力啊。
5. `selenium`算是一个跨浏览器的库。因为这个原因，用的人比起上面非官方py封装的库多不少，更新也更及时。可以更好的控制打开和关闭浏览器。。。就用这个好了。


### 20180513
> 刚完成了selenium抓取，又研究了一下这个网站，发现有办法可以直接获取到mp4地址！准备再次改动。本来还打算研究一下为什么splash不能正确渲染的，发现safari无法正常渲染这个网站。而splash用的就是webkit内核，所以这个坑我就留到以后去挖吧。。ps:不知道为什么46ek打不开了。另外说一下selenium效率确实低了不少


### 20180521
> 搁置了这么久。因为发现m3u8的时长信息，必须要获取整个文件才能计算得到时长，由于分割得特别细，差不多有50Kb以上的大小。之前的mp4信息，因为网络比较快，没有进行异步处理。现在这个因为阻塞的原因。完全没有程序的效率可言了。。看了很多的源码还有其他工具。。还是改成中间件的方式来吧

### 20180603
> 本来终于完成了。但是好想是今天jav网站做了变动。获取地址的时候，不加rand参数，会导致解析出来的结果用不了。明天把解密函数用python实现一下吧。顺便补习一下js

### 20180714
> 最近一段事件特别忙，公司搬家。今天提交一下。算是搞定了。

### 20181023
> 我也不知道现在能不能跑。。不过我转移到了gitlab